nina<-read.csv("C:/Users/Stephen/Desktop/Nina.csv", header=T)
library(forcast)
library(forecast)
forecast(nina)
nina
summary(nina)
nina<-read.csv("C:/Users/Stephen/Desktop/Nina.csv", header=T)
forecast(nina)
summary(nina)
library(lubridate)
nina$Month<-as.Date(nina$Month)
nina<-read.csv("C:/Users/Stephen/Desktop/Nina.csv", header=T)
summary(nina)
nina$Month<-as.Date(nina$Month)
forecast(nina)
forecast(nina$Referrals)
plot(forecast(nina$Referrals))
hist(nina$Referrals)
library(ggplot2)
qplot(nina$Referrals)
qplot(nina)
plot(nina)
?tbs
?bts
?forecast
?tbats
tbats(nina$Referrals)
tbats(nina$Referrals, num.cores=5)
tbats(nina, num.cores=5)
ets(nina)
ets(nina$Referrals)
plot(ets(nina$Referrals))
tbats(c(1. 2, 4))
test<-c(1, 2, 4)
tbats(test)
install.packages("deldir")
install.packages(c("AppliedPredictiveModeling", "C50", "deldir", "lme4", "mice", "minqa", "party", "plotmo", "rattle", "Rcpp", "rgdal"))
train_v2 <- read.csv("F:/Loans/train_v2.csv")
View(train_v2)
test_v2 <- read.csv("F:/Loans/test_v2.csv")
View(test_v2)
train<-train_v2
test<-test_v2
pred <- train[ , ncol(train), drop = TRUE]
train <- train[-ncol(train)]
train <- train[-1]
train.attr <- data.frame(
Minimum = apply(train, 2, min, na.rm = TRUE),
Maximum = apply(train, 2, max, na.rm = TRUE),
Range = apply(train, 2, max, na.rm = TRUE) - apply(train, 2, min, na.rm = TRUE),
Mean = apply(train, 2, mean, na.rm = TRUE),
StDev =  apply(train, 2, sd, na.rm = TRUE),
CV = apply(train, 2, function(x){
if(mean(x, na.rm = TRUE) == 0){0}
else{sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)}}),
Outliers = apply(train, 2, function(x){length(boxplot(x, plot = FALSE)$out)}),
NAs = apply(train, 2, function(x){sum(is.na(x))}),
IsInteger = apply(train, 2, function(x){(all.equal(x, as.integer(x)) == TRUE) * 1}),
IsSortedAsc = apply(train, 2, function(x){(all.equal(x[!is.na(x)], sort(x, na.last = NA)) == TRUE) * 1}),
IsSortedDesc = apply(train, 2, function(x){(all.equal(x[!is.na(x)], sort(x, na.last = NA, decreasing = TRUE)) == TRUE) * 1}),
UniqueValues = apply(train, 2, function(x){length(unique(x))}),
CorToPred = apply(train, 2, function(x){cor(pred, x, use = "complete.obs")})
)
train.attr$CorToPred[is.na(train.attr$CorToPred)] <- 0
train.attr.scaled <- scale(train.attr[ , c("Range", "CV", "Outliers", "NAs", "IsInteger", "UniqueValues", "CorToPred")])
hCluster <- hclust(dist(train.attr.scaled), "ward")
plot(hCluster)
train.attr$ClusterNo <- cutree(hCluster, k = 20)
Events <- read.csv("E:/PGi/Model/Clean Data/Events.csv")
View(Events)
str(Events)
hist(Events$OPERATOR)
table(Events$OPERATOR)
order(table(Events$OPERATOR))
rank(table(Events$OPERATOR))
sort(table(Events$OPERATOR))
plot(sort(table(Events$OPERATOR)))
plot(table(Events$OPERATOR))
hist(table(Events$OPERATOR))
library(ggplot2)
qplot(sort(table(Events$OPERATOR)))
qplot(table(Events$OPERATOR))
qplot(table(Events$OPERATOR), geom_bar)
qplot(table(Events$OPERATOR), geom_histogram)
?count
Count?
)
library(reshape2)
melt(Events)
blah<-melt(Events)
blah<-melt(Events$OPERATOR)
cast(blah, ~., fun=sum)
dcast(blah, ~., fun=sum)
dcast(blah, OPERATOR~., fun=sum)
dcast(blah, blah~., fun=sum)
aggregate(blah)
aggregate(blah, fun=sum)
aggregate(blah, FUN=sum)
aggregate(blah, by=list(blah$value) FUN=sum)
aggregate(blah, by=list(blah$value), FUN=sum)
aggregate(blah, by=list(blah$value), FUN=count)
dcast(blah, blah$value~., sum)
dcast(blah, blah$value~., count)
as.data.frame(table(Events$OPERATOR))
blah<-as.data.frame(table(Events$OPERATOR))
blah
blerg<-melt(blah)
dcast(blerg, var1~., sum)
dcast(blerg, Var1~., sum)
install.packages(c("cairoDevice", "caret", "denstrip", "doParallel", "doSNOW", "dynlm", "maptools", "pROC", "RcppArmadillo", "rFerns", "RGtk2", "spatstat", "testthat"))
library(C50)
data(churn)
str(churnTrain)
library(caret)
install.packages("caret")
library(caret)
set.seed(1)
?YeoJohnson
str(churnTest)
forGBM<-churnTrain
forGBM$churn<-ifelse(forGBM$churn=="yes", 1, 0)
gbmTune<-train(x=churnTrain[,predictors], y=churnTrain$churn, method="gbm")
gbmTune<-train(churn~., data=churnTrain, method="gbm", verbose=F)
ctrl<-trainControl(method="repeatedcv", repeats=5, classProbs=T, summaryFunction=twoClassSummary)
gbmTune<-train(churn~., data=churnTrain, method="gbm", verbose=F, metric="ROC", trControl=ctrl)
ctrl<-trainControl(method="repeatedcv", repeats=5, classProbs=T, summaryFunction=twoClassSummary)
grid<-expand.grid(.interaction.depth=seq(1, 7, by=2), .n.trees=seq(100, 1000, by=50), .shrinkage=c(0.01, 0.1))
gbmTune<-train(churn~., data=churnTrain, method="gbm", verbose=F, metric="ROC", trControl=ctrl)
gbmTune
gbmTune$modelInfo
gbmTune$results
gbmTune
ggplot(gbmTune)
ggplot(gbmTune) + theme(legend.position="top")
gbmTune$results
gbmTune$bestTune
gbmTune$modelInfo
gbmTune$modelType
gbmTune$perfNames
gbmProb<-predict(gbmTune, churnTest, type="prob")
confusionMatrix(gbmPred, churnTest$churn)
gbmPred<-predict(gbmTune, churnTest)
confusionMatrix(gbmPred, churnTest$churn)
install.packages(c("Hmisc", "plyr", "spam"))
install.packages(c("doSNOW", "lava", "lme4", "plotrix", "Rcpp"))
install.packages("Metrics")
install.packages("dplyr")
install.packages("e1071")
library(kernlab)
data(iris)
kpc<-kpca(iris$Species~., kernel="rbfdot")
library(dplyr)
blah<-select(iris, -Species)
kpc<-kpca(~., data=blah kernel="rbfdot")
kpc<-kpca(~., data=blah, kernel="rbfdot")
pcv(kpc)
plot(kpc)
screeplotkpc
str(kpc)
plot(pcv)
plot(rotated)
plot(eig)
screeplot(pcv(kpc))
boo<-pcv(kpc)
screeplot(boo
)
plot(pcv(kpc))
plot(rotated(kpc))
library(rTensor)
install.packages("rTensor")
library(rTensor)
mpca(blah)
mpca(blah, ranks=NULL)
mpca(blah, ranks=NULL, max_iter=25)
mpca(blah, ranks=3)
princomp(blah)
foo<-princomp(blah)
plot(foo)
screeplot(foo)
install.packages("effects")
install.packages("twang")
install.packages(c("forecast", "partykit", "rFerns", "rgeos", "rpart", "RWeka"))
Budget <- read.csv("F:/Cyntia/Job/Job/Budget.csv")
View(Budget)
x<-4
class(x)
x<-c(4, "a", TRUE)
class(x)
x <- list(2, "a", "b", TRUE)
x[[2]]
x <- c(17, 14, 4, 5, 13, 12, 10)
x[x >= 11] <- 4
x
x <- list(2, "a", "b", TRUE)
foo<-x[[2]]
foo
class(foo)
hw1_data <- read.csv("C:/Users/Stephen/Desktop/hw1_data.csv")
View(hw1_data)
blah<-hw1_data
head(blah, 2)
nrows(blah)
nrow(blah)
tail(blah, 2)
blah$Ozone[47]
summary(blah$Ozone)
library(dplyr)
foo<-filter(blah, Ozone>31 & Temp >90)
summary(foo)
foo<-filter(blah, Month==6)
summary(foo)
foo<-filter(blah, Month==5)
summary(foo)
?download.file
gcd<-download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv )
gcd<-download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv)
gcd<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
gcd<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", gcd.csv)
gcd<-download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "gcd.csv")
gcd <- read.csv("~/GitHub/Coursera/gcd.csv")
View(gcd)
gcd %.%
filter(Val=24) %.%
count(n)
gcd %.%
filter(Val==24) %.%
count(n)
gcd %.%
filter(VAL==24) %.%
count(n)
gcd %.%
filter(VAL==24) %.%
count=n()
gcd %.%
filter(VAL==24) %.%
summarise(count=n())
summary(gcd$FES)
?read.csv
NGAP<-read.csv("C:/Users/Stephen/Desktop", skip=8, nrows=5)
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=8, nrows=5)
View(NGAP)
foo<-NGAP[,7:14]
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=8, nrows=5, header=T)
foo<-NGAP[,7:14]
View(foo)
foo<-NGAP[7:14,]
View(foo)
View(NGAP)
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=8, nrows=5)
View(NGAP)
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=18, nrows=5, col.names=18)
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=18, nrows=5)
View(NGAP)
NGAP<-read.csv("C:/Users/Stephen/Desktop/NGAP.csv", skip=17, nrows=5)
View(NGAP)
foo<-NGAP[, 7:15]
View(foo)
dat<-foo
sum(dat$Zip*dat$Ext,na.rm=T)
install.packages("xlsx")
install.packages(c("BH", "foreach", "hts", "iterators", "mvtnorm", "rTensor", "sp"))
library(dplyr)
install.packages(c("dplyr", "forecast", "caret", "stringr", "lubridate"))
install.packages(c("AppliedPredictiveModeling", "hts"))
install.packages("BH")
install.packages(c('Rcompression', 'XML'))
install.packages(c('ROOXML', 'RExcelXML'), repos = 'http://www.omegahat.org/R', type = 'source')
install.packages(c("memoise", "reshape2", "scales"))
install.packages(c("car", "evaluate"))
install.packages("RcppArmadillo")
install.packages(c("CORElearn", "forecast", "markdown"))
install.packages(c("dplyr", "ggplot2"))
SoOScores <- read.delim("C:/Users/Stephen/Desktop/SoOScores.tsv")
View(SoOScores)
SO<-SoOScores
library(stringr)
install.packages("caret")
install.packages(c("caret", "mapdata", "maps", "maptools", "RcppArmadillo"))
install.packages(c("hts", "rjson"))
install.packages("BradleyTerry2")
churn <- read.csv("E:/data/churn/churn.txt")
View(churn)
library(caret)
library(plyr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
setwd("E:/Github Stuff")
train <- read.delim("E:/kaggle/RT Movie Reviews/train.tsv")
View(train)
install.packages("tm")
test <- read.delim("E:/kaggle/RT Movie Reviews/test.tsv")
View(test)
train <- read.delim("E:/kaggle/RT Movie Reviews/train.tsv")
View(train)
test <- read.delim("E:/kaggle/RT Movie Reviews/test.tsv")
View(test)
library(tm)
install.packages("slam")
library(tm)
foo<-Corpus(VectorSource(train$Phrase))
myCorpus <- tm_map(myCorpus, tolower)
install.packages("ggvis")
churn <- read.csv("E:/Github Stuff/srepho.github.io/churn.txt")
View(churn)
library(ggplot2)
ggplot(churn, aes(x=Account.Length))
ggplot(churn, aes(x=Account.Length))+geom_boxplot()
ggplot(churn, aes(x=Account.Length))+geom_histogram()
ggplot(churn, aes(x=Account.Length, color=Churn.))+geom_histogram()
ggplot(churn, aes(x=Account.Length))+geom_histogram(color=Churn.)
ggplot(churn, aes(x=Account.Length))+geom_histogram(color=churn.)
ggplot(churn, aes(x=Account.Length))+geom_histogram(position="dodge")
ggplot(churn, aes(x=Account.Length, color=Churn.))+geom_histogram(position="dodge")
ggplot(churn, aes(x=Account.Length, fill=Churn.))+geom_histogram(position="dodge")
ggplot(churn, aes(x=Account.Length, fill=Churn.))+geom_histogram()+ facet_grid(Churn. ~ .)
ggplot(churn, aes(x=Account.Length, fill=Churn.))+geom_density()+ facet_grid(Churn. ~ .)
ggplot(churn, aes(x=VMail.Message, fill=Churn.))+geom_density()+ facet_grid(Churn. ~ .)
ggplot(churn, aes(x=CustSer.Calls, fill=Churn.))+geom_density()+ facet_grid(Churn. ~ .)
ggplot(churn, aes(x=CustServ.Calls, fill=Churn.))+geom_density()+ facet_grid(Churn. ~ .)
ggplot(churn, aes(x=CustServ.Calls, fill=Churn.))+geom_histogram()+ facet_grid(Churn. ~ .)
ggplot(churn, aes(x=CustServ.Calls, fill=Churn.))+geom_boxplot()+ facet_grid(Churn. ~ .)
ggplot(churn, aes(x=CustServ.Calls, y=Churn.))+geom_boxplot()+ facet_grid(Churn. ~ .)
ggplot(churn, aes(y=CustServ.Calls, color=Churn.))+geom_boxplot()+ facet_grid(Churn. ~ .)
ggplot(churn, aes(y=CustServ.Calls, x=Churn.))+geom_boxplot()+ facet_grid(Churn. ~ .)
ggplot(churn, aes(y=CustServ.Calls, x=Churn.))+geom_boxplot()
ggplot(churn, aes(y=CustServ.Calls, x=Churn.))+geom_boxplot()+ geom_jitter()
library(caret)
library(rpart)
fit<-rpart(churn$Churn.~., data=churn, method="class")
plotcp(fit)
summart(fit)
summary(fit)
printcp(fit)
plot(fit)
plot(fit, uniform=T)
plot(fit, uniform=TRUE,
main="Classification Tree for Kyphosis")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
fit<-train(churn$Churn.~., data=churn, method="rpart")
plot(fit)
plot(fit$method)
fit$method
fit$modelInfo
plot(fit$modelInfo)
fit$metric
fit$xlevels
fit$coefnames
summary(fit)
fit
install.packages("ggvis")
install.packages("Formula")
install.packages("SparseM")
install.packages("hts")
install.packages("tidyr")
install.packages(c("RCurl", "RJSONIO"))
setwd("E:/Github Stuff/srepho.github.io/Churn")
churn <- read.csv("E:/Github Stuff/srepho.github.io/Churn/churn.txt")
View(churn)
library(plyr)
library(dplyr)
library(stringr)
library(ggplot2)
library(reshape2)
library(caret)
?trainControl
set.seed(12)
trainIndex <- caret::createDataPartition(churn$Churn., p = .75, list = FALSE, times = 1)
churnTrain <- churn[ trainIndex,]
churnTest <- churn[-trainIndex, ]
churnTrain$Phone<-NULL
churnTest$Phone<-NULL
churnTrain$Area.Code<-as.factor(churnTrain$Area.Code)
churnTest$Area.Code<-as.factor(churnTest$Area.Code)
set.seed(12)
lrmodel<-train(churnTrain$Churn.~., data=churnTrain, method="rf", trainControl = (method = "repeatedcv", number = 10, repeats = 5, classProbs = TRUE, summaryFunction = twoClassSummary), metric="Kappa")
lrmodel<-train(churnTrain$Churn.~., data=churnTrain, method="rf", trainControl = c(method = "repeatedcv", number = 10, repeats = 5, classProbs = TRUE, summaryFunction = twoClassSummary), metric="Kappa")
set.seed(12)
lrmodel<-train(churnTrain$Churn.~., data=churnTrain, method="rf", trainControl = c(method = "adaptive_cv", number = 10, repeats = 5, classProbs = TRUE, summaryFunction = twoClassSummary, adaptive = list(min = 10, alpha = 0.05, method = "gls", complete = TRUE)), metric="Kappa")
lrmodel
plot(lrmodel)
head(twoClassSummary)
?confusionMatrix
confusionMatrix(lrmodel)
